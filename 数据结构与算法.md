## 1.说说一个算法有哪些时间复杂度？归并算法时间复杂度是多少？

O(1) < O(logn) < O(n) < O(nlogn) < O(n^2) < O(n^3) < O(2^n)

归并算法时间复杂度是O(nlogn)

## 2.说说数组时间复杂度，什么场景下使用？

数组插入和删除操作的时间复杂度是O(n)。而数组是有序的，可以直接通过下标访问元素，十分高效，访问时间复杂度是O(1)（常数时间复杂度）。

**如果某些场景需要频繁插入和删除元素时，这时候不宜选用数组作为数据结构**。

频繁访问的场景下，可以使用数组。

## 3.说说vector的实现原理

vector是数组的进一步封装，它是一个类。可以比数组**更加灵活的处理内存空间**。

vector是动态空间，随着元素的加入，它的内部机制会自动扩充空间以容纳新的元素。vector在增加元素时，如果超过自身最大的容量Capacity，vector则将自身的容量**扩充为原来的两倍（或者1.5倍看编译器）**。扩充空间需要经过的步骤：重新配置空间，元素移动，释放旧的内存空间。一旦vector空间重新配置，则指向原来vector的所有迭代器都失效了，因为vector的地址改变了。

## 4.简述数据结构栈

栈是一种线性表，其限制只能在表尾进行插入或删除操作。由于该特性又称为后进先出的线性表。

## 5.总结一下数组与链表的区别

1. 数组内存连续、有序；链表内存可以不连续
2. 数组可以直接访问下标，访问时间复杂度O(1)；链表需要通过下一级指针层层递进访问，访问时间复杂度O(n)
3. 数组插入或删除元素时需要移动后面的元素，时间复杂度O(n)；而链表插入或删除元素时，时间复杂度O(1)
4. 频繁访问元素的场景用数组；频繁插入或删除的场景用链表

## 6.栈和队列的区别

主要区别就是规定不同。

栈规定：元素先入后出（First In Last Out， 简称FILO）。

队列规定：元素先入先出（First In First Out， 简称FIFO）。

## 7.说说二叉堆

堆是一个近似完全二叉树的结构，并同时满足堆的性质：**即子结点的键值或索引总是小于（或者大于）它的父节点**。

1.最大堆。最大堆的任何一个父节点的值， 都大于或等于它左、 右孩子节点的值。

2.最小堆。最小堆的任何一个父节点的值， 都小于或等于它左、 右孩子节点的值

## 8.说说哈希表

哈希表是一个非常有用的数据结构。可以实现**常数时间复杂度**的查找。
哈希表的做法是，**将键值对放入数组中**。因为数组可以通过下标实现**常数时间复杂度**的查找。这样相当于就找了键，也就找到了对应的值。
键值对通过**取模**或**位运算**操作来获取**哈希值**，这个哈希值就对应数组的**下标**。数组一开始会申请一定数量的内存空间，当键值对多起来后，就需要**两倍扩容**。在获取哈希值的过程中，可能出现哈**希冲突**，解决办法有开发地址法、二次探测法、链地址法。

## 9.说说堆排序的时间复杂度，建堆的时间复杂度

建堆过程的时间复杂度是O(n)，堆排序的时间复杂度是O(nlogn)

## 10.哈希表如何解决哈希冲突

1. 开放地址法（线性探测法）：如果得到的哈希地址冲突(该位置上已存储数据)的话 ，我们就是将这个数据插到下一个位置，要是下个位置也已存储数据 ，就继续到下一个，直到找到正确的可以插入的数据 。
2. 二次探测法：当遇到冲突后 ，下次所找到的位置为当前的位置加上**n的二次方**
3. 链地址法：如果得到的哈希地址冲突， 只需要插入到对应的链表中即可。

## 11.哈希表的初始数组容量一般为多少，为什么？

16。

1.需要是2的指数，因为这样可以保证hash分布均衡，减少哈希冲突

2.效率问题，如果为4，一开始就得频繁扩容，效率低；如果为64，浪费数组空间。

## 12.哈希表的负载因子为什么是0.75？

还是一样的，数值太少，频繁扩容；数值太大，容易哈希冲突。

## 13.说说红黑树

![图片说明](数据结构与算法.assets/9EB9CD58B9EA5E04C890326B5C1F471F)
**红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍**。具体来说，红黑树是满足如下条件的二叉查找树（binary search tree）：

1.每个节点要么是红色，要么是黑色。

2.根节点必须是黑色

3.红色节点不能连续（也即是，红色节点的孩子和父亲都不能是红色）。

4.对于每个节点，从该点至`null`（树尾端）的任何路径，都含有相同个数的黑色节点。

在树的结构发生改变时（插入或者删除操作），往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的条件。

## 14.说说什么是稳定的排序？

- **稳定**：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。
- **不稳定**：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。

冒泡排序、归并排序是稳定排序；快速排序是不稳定排序。

## 15.说说动态规划算法

暴力解法有很多重复计算，动态规划就是为了帮助我们减少重复计算，所以动态规划**提前存储前面计算的值，后面的值来源于已经存储的值，或者只需要在已经存储的值的基础上简单的叠加，这就是动态规划的本质，空间换时间**。

## 16.B树与B+树的区别

1.B树每个节点都存储数据，所有节点组成这棵树。B+树只有叶子节点存储数据（B+数中有两个头指针：一个指向根节点，另一个指向关键字最小的叶节点），叶子节点包含了这棵树的所有数据，所有的叶子结点使用链表相连，便于区间查找和遍历，所有非叶节点起到索引作用。

2.B树中叶节点包含的关键字和其他节点包含的关键字是不重复的，B+树的索引项只包含对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。

3.B树查找，中途内部节点处可能停止返回，所以B树查找时间复杂度不稳定；B+树中查找，无论查找是否成功，每次都是一条从根节点到叶节点的路径，查找时间复杂度稳定。

4.B+树的叶子节点通过链表相连，所以B+树范围查找比B树效率高。

**B树和B+树的共同优点**
考虑磁盘IO的影响，它相对于内存来说是很慢的。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。所以我们要减少IO次数，对于树来说，IO次数就是树的高度，而“矮胖”就是b树和B+树的特征之一，m的大小取决于磁盘页的大小。

## 17.B树的作用

B树大多用在磁盘上用于查找磁盘的地址。因为磁盘会有大量的数据，有可能没有办法一次将需要的所有数据加入到内存中，所以只能逐一加载磁盘页，每个磁盘页就对应一个节点，而对于B树来说，B树很好的将树的高度降低了，这样就会减少IO查询次数，虽然一次加载到内存的数据变多了，但速度绝对快于AVL或是红黑树的。

## 18.AVL树和红黑树的区别

红黑树的算法时间复杂度和AVL相同，但**统计性能**比AVL树更高。

> 1、红黑树和AVL树都能够以$O(log_2 n)$的时间复杂度进行搜索、插入、删除操作。 
>
> 2、由于设计，红黑树的任何不平衡都会在三次旋转之内解决。AVL树增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。

在**查找**方面： 红黑树的性质(最长路径长度不超过最短路径长度的2倍)，其查找代价基本维持在$O(logN)$左右，但在最差情况下(最长路径是最短路径的2倍少1)，比AVL要略逊色一点。 AVL是严格平衡的二叉查找树（平衡因子不超过1）。查找过程中不会出现最差情况的单支树。因此查找效率最好，最坏情况都是$O(logN)$数量级的。

所以，综上： AVL比RBtree更加平衡，但是AVL的插入和删除会带来大量的旋转。 所以如果**插入和删除比较多**的情况，应该使用**RBtree**, 如果**查询操作比较多**，应该使用**AVL**。

> AVL是一种高度平衡的二叉树，维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。当然，如果场景中对插入删除不频繁，只是对查找特别有要求，AVL还是优于红黑的。

## 19.数据库为什么使用B+树，而不使用AVL或者红黑树

我们假设B+树一个节点可以有100个关键字，那么3层的B树可以容纳大概1000000多个关键字（100+101*100+101*101*100）。而红黑树要存储这么多至少要20层。所以使用B树相对于红黑树和AVL可以**减少IO操作**

## 20.增加B+树的路数可以降低树的高度，那么无限增加树的路数是不是可以有最优的查找效率？

不可以。因为这样会形成一个有序数组，文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大的话，不一定能一次性加载到内存中。有序数组没法一次性加载进内存，这时候B+树的多路存储威力就出来了，可以每次加载B+树的一个结点，然后一步步往下找。

## 21.简述二叉树的前中后序遍历算法

前序遍历：若二叉树为空树，则执行空逻辑，否则：

1. 访问根节点
2. 递归前序遍历左子树
3. 递归前序遍历右子树

中序遍历：若二叉树为空树，则执行空逻辑，否则：

1. 递归中序遍历左子树
2. 访问根节点
3. 递归中序遍历右子树

后序遍历：若二叉树为空树，则执行空逻辑，否则：

1. 递归后序遍历左子树
2. 递归后序遍历右子树
3. 访问根节点

## 22.简述二叉树

二叉树是n个有限元素的集合，该集合或者为空、或者由一个称为根（root）的元素及两个不相交的、被分别称为左子树和右子树的二叉树组成。

## 23.简述满二叉树

一个二叉树，如果除了叶子节点的其他的结点数都达到最大值，则这个二叉树就是满二叉树。

## 24.简述完全二叉树

一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。

## 25.简述二叉查找树

1. 二叉查找树的左子树若不为空，则左子树上所有结点的值均小于它的根结点的值；
2. 二叉查找树的右子树若不为空，则右子树上所有结点的值均大于它的根结点的值；
3. 二叉查找树的左、右子树也分别为二叉查找树；
4. 没有键值相等的结点。

## 26.简述AVL树

AVL树是一种改进版的搜索二叉树，其引入平衡因子（左子支高度与右子支高度之差的绝对值），通过旋转使其尽量保持平衡。 任何一个节点的左子支高度与右子支高度之差的绝对值不超过1。

## 27.常见的不稳定排序算法有哪些

选择排序、堆排序、快速排序、希尔排序

## 28.常见的稳定排序算法有哪些

插入排序、冒泡排序、归并排序

## 29.简述插入排序

插入排序：每一趟将一个待排序记录按其关键字的大小插入到已排好序的一组记录的适当位置上，直到所有待排序记录全部插入为止。

排序算法稳定。时间复杂度 O(n²)，空间复杂度 O(1)。

## 30.简述希尔排序

希尔排序：把记录按下标的一定增量分组，对每组进行直接插入排序，每次排序后减小增量，当增量减至 1 时排序完毕。

排序算法不稳定。时间复杂度 $n^{1.25-2}$，空间复杂度 O(1)。

## 31.简述直接选择排序

直接选择排序：每次在未排序序列中找到最小元素，和未排序序列的第一个元素交换位置，再在剩余未排序序列中重复该操作直到所有元素排序完毕。

排序算法不稳定。时间复杂度 O(n²)，空间复杂度 O(1)。

## 32.简述堆排序

堆排序：将待排序数组看作一个树状数组，建立一个二叉树堆。通过对这种数据结构进行每个元素的插入，完成排序工作。

排序算法不稳定，时间复杂度 O(nlogn)，空间复杂度 O(1)。

## 33.简述冒泡排序

冒泡排序：比较相邻的元素，如果第一个比第二个大就进行交换，对每一对相邻元素做同样的工作。

排序算法稳定，时间复杂度 O(n²)，空间复杂度 O(1)。

## 34.简述快速排序

快速排序：随机选择一个基准元素，通过一趟排序将要排序的数据分割成独立的两部分，一部分全部小于等于基准元素，一部分全部大于等于基准元素，再按此方法递归对这两部分数据进行快速排序。

排序算法不稳定，时间复杂度 O(nlogn)，空间复杂度 O(logn)。

## 35.简述归并排序

归并排序：将待排序序列分成两部分，然后对两部分分别递归排序，最后进行合并。 排序算法稳定，时间复杂度都为 O(nlogn)，空间复杂度为 O(n)。

## 36.简述图

图是由顶点集合和顶点之间的边集合组成的一种数据结构，分为有向图和无向图。

有向图：边具有方向性

无向图：边不具有方向性

## 37.简述邻接表

邻接表是通过链表表示图连接关系的一种方。对于表头结点所对应的顶点存在相邻顶点，则把相邻顶点依次存放于表头结点所指向的单向链表中。

## 38.说一下对于树的理解

数据结构树是一种由有限节点组成的层次关系的集合。其特点如下：

1. 每个节点有零个或多个子节点；
2. 只有一个节点没有父节点，该节点称为根节点；
3. 除根节点外，每个节点有且只有一个父节点；